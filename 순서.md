# 실행 순서
## 사용할 폴더에 이미지 캡셔닝 폴더 받기  
- git clone git@github.com:ruotianluo/ImageCaptioning.pytorch.git  
- python -m pip install -e .  

## 사용할 데이터 넣기  
1. data.zip 파일 지금 폴더로 이동  
2. cider, coco-caption 폴더 삭제   
3. git clone git@github.com:ruotianluo/cider.git  
4. git clone git@github.com:ruotianluo/coco-caption.git  
5. data.zip을 data 폴더에 옮긴 후 unzip  
  
## 필요한 패키지 install  
- pip install lmdbdict  
- conda install h5py  
- conda install pytorch torchvision torchaudio cudatoolkit=11 -c pytorch  
- conda install scikit-image  
- python scripts/prepro_labels.py --input_json data/dataset_coco.json --output_json data/cocotalk.json --output_h5 data/cocotalk\  
- conda install tensorboard  
- pip install pycocotools  
- pip install pycocoevalcap  
- transformer 설치  
  - conda install yacs  
  - pip install transformers   
  - pip install git+https://github.com/ruotianluo/meshed-memory-transformer.git  
  - pip install gensim  
  
## data 준비  
1. bu_data 폴더 생성  
  - mkdir data/bu_data  
2. cd data/bu_data  
3. wget https://imagecaption.blob.core.windows.net/imagecaption/trainval.zip  
4. unzip trainval.zip  
5. python scripts/make_bu_data.py --output_dir data/cocobu  
  
## coco-caption 폴더에서 할 일  
1. cd coco-caption  
2. bash get_stanford_models.sh  
3. (생략 가능)SPICE will try to create a cache of parsed sentences in ./pycocoevalcap/spice/cache/. This dramatically speeds up repeated evaluations. The cache directory can be moved by setting 'CACHE_DIR' in ./pycocoevalcap/spice. In the same file, caching can be turned off by removing the '-cache' argument to 'spice_cmd'.
4. bash get_google_word2vec_model.sh  
  
## 주의할 사항  
- /tools/train -> print문 지우기  
  
### spice 부분 지운거 어딘지  
- captioning/utils/eval_utils.py  
- coco-caption/pycocoevalcap/eval.py  
  
### captioning/utils/torchhalp  
- captioning 안에 utils 안에 torchhalp 폴더 추가  
  
### train.py 파일 수정 사항!!!!!  
- time_list 저장하는 부분 -> 자기 폴더 경로로 수정  
- ImageCaptioning.pytorch 폴더 안에 time_list 폴더 생성해두기  
  
## train.py 실행코드  
- python tools/train.py --cfg configs/transformer/transformer.yml --id tf  
  
## 병렬화  
- train-HALP  
  - tools/train-HALP.py 추가  
  - 경로 수정!!  
  
## eval.py 실행 코드  
- python tools/eval.py --model log_tf_f8k_base_batch30_epoch30/model-best.pth --infos_path log_tf_f8k_base_batch30_epoch30/infos_tf_f8k_base_batch30_epoch30.pkl --image_folder image_test --num_images 11
